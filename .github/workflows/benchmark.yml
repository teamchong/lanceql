name: Benchmark

on:
  push:
    branches: [main]
    paths:
      - 'src/**'
      - 'benchmarks/**'
      - 'scripts/bench-*.sh'
      - '.github/workflows/benchmark.yml'
  pull_request:
    branches: [main]
    paths:
      - 'src/**'
      - 'benchmarks/**'
      - 'scripts/bench-*.sh'
      - '.github/workflows/benchmark.yml'
  workflow_dispatch:

jobs:
  benchmark-macos:
    runs-on: macos-14  # Apple Silicon (M1)
    timeout-minutes: 60  # Each benchmark runs 30+ seconds

    steps:
      - uses: actions/checkout@v4

      - name: Setup Zig
        uses: mlugg/setup-zig@v2
        with:
          version: 0.15.2

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          brew install duckdb
          pip install polars numpy

      - name: Build Metal shaders
        run: zig build metal-shaders

      - name: Build library
        run: zig build lib

      - name: Run Vector benchmark (GPU vs CPU)
        id: bench-vector
        run: |
          echo "## Vector Operations Benchmark" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          ./scripts/bench-vector.sh 2>&1 | tee bench-vector.txt
          cat bench-vector.txt >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

      - name: Run SQL clause benchmark (LanceQL vs DuckDB vs Polars)
        id: bench-sql
        run: |
          echo "## SQL Clause Benchmark (200M rows)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          ./scripts/bench-sql.sh 2>&1 | tee bench-sql.txt
          cat bench-sql.txt >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

      - name: Run @logic_table benchmark (LanceQL vs DuckDB vs Polars)
        id: bench-logic-table
        run: |
          echo "## @logic_table ML Workflow Benchmark" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          ./scripts/bench-logic-table.sh 2>&1 | tee bench-logic-table.txt
          cat bench-logic-table.txt >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

      - name: Generate summary
        run: |
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Benchmark | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Vector Ops (GPU vs CPU) | :white_check_mark: |" >> $GITHUB_STEP_SUMMARY
          echo "| SQL Clauses (200M rows) | :white_check_mark: |" >> $GITHUB_STEP_SUMMARY
          echo "| ML Workflows | :white_check_mark: |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Platform:** macOS Apple Silicon (M1)" >> $GITHUB_STEP_SUMMARY
          echo "**Date:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY

      - name: Combine results
        run: |
          echo "=== LanceQL Benchmark Results ===" > benchmark-results.txt
          echo "Platform: macOS Apple Silicon (GPU enabled)" >> benchmark-results.txt
          echo "Date: $(date -u)" >> benchmark-results.txt
          echo "" >> benchmark-results.txt
          cat bench-vector.txt >> benchmark-results.txt
          echo "" >> benchmark-results.txt
          cat bench-sql.txt >> benchmark-results.txt
          echo "" >> benchmark-results.txt
          cat bench-logic-table.txt >> benchmark-results.txt

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-macos
          path: |
            benchmark-results.txt
            bench-*.txt
          retention-days: 30

  benchmark-linux:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - uses: actions/checkout@v4

      - name: Setup Zig
        uses: mlugg/setup-zig@v2
        with:
          version: 0.15.2

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          # Install DuckDB
          curl -LO https://github.com/duckdb/duckdb/releases/download/v1.1.3/duckdb_cli-linux-amd64.zip
          unzip duckdb_cli-linux-amd64.zip
          sudo mv duckdb /usr/local/bin/
          pip install polars numpy

      - name: Build library
        run: zig build lib

      - name: Run SQL clause benchmark (LanceQL vs DuckDB vs Polars)
        run: |
          echo "## SQL Clause Benchmark (Linux - 200M rows)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          ./scripts/bench-sql.sh 2>&1 | tee bench-sql.txt
          cat bench-sql.txt >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

      - name: Run @logic_table benchmark (LanceQL vs DuckDB vs Polars)
        run: |
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## @logic_table ML Workflow Benchmark (Linux)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          ./scripts/bench-logic-table.sh 2>&1 | tee bench-logic-table.txt
          cat bench-logic-table.txt >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

      - name: Generate summary
        run: |
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Summary (Linux)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Benchmark | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| SQL Clauses (200M rows) | :white_check_mark: |" >> $GITHUB_STEP_SUMMARY
          echo "| ML Workflows | :white_check_mark: |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Platform:** Linux x86_64 (CPU only)" >> $GITHUB_STEP_SUMMARY
          echo "**Date:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-linux
          path: bench-*.txt
          retention-days: 30

  compare-results:
    needs: [benchmark-linux, benchmark-macos]
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'

    steps:
      - name: Download Linux results
        uses: actions/download-artifact@v4
        with:
          name: benchmark-results-linux
          path: linux

      - name: Download macOS results
        uses: actions/download-artifact@v4
        with:
          name: benchmark-results-macos
          path: macos

      - name: Comment benchmark results on PR
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            let comment = '## LanceQL Benchmark Results\n\n';
            comment += 'All benchmarks run 30+ seconds each to ensure fair comparison (no cold-start bias).\n\n';

            try {
              comment += '### macOS (Apple Silicon + GPU)\n\n';

              if (fs.existsSync('macos/bench-vector.txt')) {
                comment += '
#### Vector Operations\n```\n';
                comment += fs.readFileSync('macos/bench-vector.txt', 'utf8').slice(0, 3000);
                comment += '\n```\n\n';
              }

              if (fs.existsSync('macos/bench-sql.txt')) {
                comment += '
#### SQL Clauses (200M rows)\n```\n';
                comment += fs.readFileSync('macos/bench-sql.txt', 'utf8').slice(0, 3000);
                comment += '\n```\n\n';
              }

              if (fs.existsSync('macos/bench-logic-table.txt')) {
                comment += '
#### ML Workflows\n```\n';
                comment += fs.readFileSync('macos/bench-logic-table.txt', 'utf8').slice(0, 3000);
                comment += '\n```\n\n';
              }
            } catch (e) {
              comment += '_macOS results not available_\n\n';
            }

            try {
              comment += '### Linux (CPU only)\n\n';

              if (fs.existsSync('linux/bench-sql.txt')) {
                comment += '
#### SQL Clauses\n```\n';
                comment += fs.readFileSync('linux/bench-sql.txt', 'utf8').slice(0, 3000);
                comment += '\n```\n\n';
              }
            } catch (e) {
              comment += '_Linux results not available_\n';
            }

            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const existingComment = comments.find(c =>
              c.user.type === 'Bot' && c.body.includes('LanceQL Benchmark Results')
            );

            if (existingComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existingComment.id,
                body: comment
              });
            } else {
              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            }
