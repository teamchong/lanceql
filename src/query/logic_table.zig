//! LogicTable Protocol - Interface between metal0 compiled code and lanceql executor
//!
//! This module provides the runtime for executing @logic_table compiled methods
//! with data from Lance tables. It handles:
//! - Column data storage (pre-loaded column arrays)
//! - Batch function dispatch (GPU/SIMD/scalar)
//!
//! ## Usage
//!
//! ```zig
//! // Create context and bind column data
//! var ctx = LogicTableContext.init(allocator);
//! defer ctx.deinit();
//!
//! try ctx.bindColumnF32("docs.embedding", docs_embedding_data);
//! try ctx.bindColumnF32("query.embedding", query_embedding_data);
//!
//! // Execute batch operations
//! const scores = try batchCosineSimilarity(allocator, query_vec, doc_vecs, 384);
//! ```

const std = @import("std");
const metal = @import("lanceql.metal");

/// Dispatch threshold for GPU vs CPU
const GPU_THRESHOLD: usize = 10_000;
const SIMD_THRESHOLD: usize = 16;

/// Column dependency metadata
pub const ColumnDep = struct {
    table: []const u8,
    column: []const u8,
};

/// Method metadata - generated by metal0 for each @logic_table method
pub const MethodMeta = struct {
    name: []const u8,
    deps: []const ColumnDep,
};

/// Errors from LogicTable execution
pub const LogicTableError = error{
    ColumnNotBound,
    ColumnNotFound,
    MethodNotFound,
    TypeMismatch,
    DimensionMismatch,
    OutOfMemory,
    GPUError,
    InvalidLogicTable,
};

/// Runtime context for executing LogicTable methods
/// Stores pre-loaded column data for batch operations
pub const LogicTableContext = struct {
    allocator: std.mem.Allocator,

    /// Cached column data: "table.column" â†’ slice
    column_cache: std.StringHashMap([]const f32),

    /// Owned keys that need to be freed
    owned_keys: std.ArrayListUnmanaged([]const u8),

    const Self = @This();

    pub fn init(allocator: std.mem.Allocator) Self {
        return .{
            .allocator = allocator,
            .column_cache = std.StringHashMap([]const f32).init(allocator),
            .owned_keys = .{},
        };
    }

    pub fn deinit(self: *Self) void {
        // Free owned keys
        for (self.owned_keys.items) |key| {
            self.allocator.free(key);
        }
        self.owned_keys.deinit(self.allocator);
        self.column_cache.deinit();
    }

    /// Bind column data with a key like "table.column"
    pub fn bindColumnF32(self: *Self, key: []const u8, data: []const f32) LogicTableError!void {
        const key_copy = self.allocator.dupe(u8, key) catch return LogicTableError.OutOfMemory;
        errdefer self.allocator.free(key_copy);

        self.column_cache.put(key_copy, data) catch return LogicTableError.OutOfMemory;
        self.owned_keys.append(self.allocator, key_copy) catch return LogicTableError.OutOfMemory;
    }

    /// Bind column data with table alias and column name
    pub fn bindColumn(self: *Self, table_alias: []const u8, column_name: []const u8, data: []const f32) LogicTableError!void {
        var key_buf: [256]u8 = undefined;
        const key = std.fmt.bufPrint(&key_buf, "{s}.{s}", .{ table_alias, column_name }) catch
            return LogicTableError.OutOfMemory;
        return self.bindColumnF32(key, data);
    }

    /// Get bound column data
    pub fn getColumnF32(self: *const Self, key: []const u8) ?[]const f32 {
        return self.column_cache.get(key);
    }

    /// Get column data by table alias and column name
    pub fn getColumn(self: *const Self, table_alias: []const u8, column_name: []const u8) LogicTableError![]const f32 {
        var key_buf: [256]u8 = undefined;
        const key = std.fmt.bufPrint(&key_buf, "{s}.{s}", .{ table_alias, column_name }) catch
            return LogicTableError.OutOfMemory;

        return self.column_cache.get(key) orelse LogicTableError.ColumnNotBound;
    }

    /// Load dependencies for a method
    pub fn loadDependencies(self: *const Self, deps: []const ColumnDep) LogicTableError![][]const f32 {
        var result = self.allocator.alloc([]const f32, deps.len) catch
            return LogicTableError.OutOfMemory;
        errdefer self.allocator.free(result);

        for (deps, 0..) |dep, i| {
            result[i] = try self.getColumn(dep.table, dep.column);
        }

        return result;
    }
};

// =============================================================================
// Batch Vector Operations (GPU/SIMD dispatch)
// =============================================================================

/// Cosine similarity between query vector and batch of document vectors
/// GPU dispatch for large batches, SIMD for medium, scalar for small
pub fn batchCosineSimilarity(
    allocator: std.mem.Allocator,
    query: []const f32,
    docs: []const f32, // Flattened: [num_docs * dim]
    dim: usize,
) LogicTableError![]f32 {
    const num_docs = docs.len / dim;
    var out = allocator.alloc(f32, num_docs) catch return LogicTableError.OutOfMemory;
    errdefer allocator.free(out);

    // GPU path for large batches (handles fallback internally)
    if (comptime metal.use_metal) {
        if (num_docs >= GPU_THRESHOLD and metal.isGPUReady()) {
            metal.gpuCosineSimilarityBatch(query, docs, dim, out);
            return out;
        }
    }

    // CPU path with SIMD
    const query_norm = vectorNorm(query);
    if (query_norm == 0) {
        @memset(out, 0);
        return out;
    }

    for (0..num_docs) |i| {
        const doc_start = i * dim;
        const doc = docs[doc_start..][0..dim];
        const dot = vectorDot(query, doc);
        const doc_norm = vectorNorm(doc);
        out[i] = if (doc_norm > 0) dot / (query_norm * doc_norm) else 0;
    }

    return out;
}

/// L2 (Euclidean) distance between query vector and batch of document vectors
pub fn batchL2Distance(
    allocator: std.mem.Allocator,
    query: []const f32,
    docs: []const f32,
    dim: usize,
) LogicTableError![]f32 {
    const num_docs = docs.len / dim;
    var out = allocator.alloc(f32, num_docs) catch return LogicTableError.OutOfMemory;
    errdefer allocator.free(out);

    for (0..num_docs) |i| {
        const doc_start = i * dim;
        const doc = docs[doc_start..][0..dim];
        var sum: f32 = 0;
        for (0..dim) |j| {
            const diff = query[j] - doc[j];
            sum += diff * diff;
        }
        out[i] = @sqrt(sum);
    }

    return out;
}

/// Dot product between query vector and batch of document vectors
pub fn batchDotProduct(
    allocator: std.mem.Allocator,
    query: []const f32,
    docs: []const f32,
    dim: usize,
) LogicTableError![]f32 {
    const num_docs = docs.len / dim;
    var out = allocator.alloc(f32, num_docs) catch return LogicTableError.OutOfMemory;
    errdefer allocator.free(out);

    // GPU path (handles fallback internally)
    if (comptime metal.use_metal) {
        if (num_docs >= GPU_THRESHOLD and metal.isGPUReady()) {
            metal.gpuDotProductBatch(query, docs, dim, out);
            return out;
        }
    }

    // CPU path
    for (0..num_docs) |i| {
        const doc_start = i * dim;
        const doc = docs[doc_start..][0..dim];
        out[i] = vectorDot(query, doc);
    }

    return out;
}

// =============================================================================
// SIMD Vector Primitives
// =============================================================================

/// Dot product of two vectors
fn vectorDot(a: []const f32, b: []const f32) f32 {
    const len = @min(a.len, b.len);
    var sum: f32 = 0;

    // SIMD path for vectors >= 8 elements
    if (len >= 8) {
        const Vec8 = @Vector(8, f32);
        var i: usize = 0;
        var simd_sum: Vec8 = @splat(0);

        while (i + 8 <= len) : (i += 8) {
            const va: Vec8 = a[i..][0..8].*;
            const vb: Vec8 = b[i..][0..8].*;
            simd_sum += va * vb;
        }

        // Horizontal sum
        sum = @reduce(.Add, simd_sum);

        // Handle remainder
        while (i < len) : (i += 1) {
            sum += a[i] * b[i];
        }
    } else {
        // Scalar path
        for (0..len) |i| {
            sum += a[i] * b[i];
        }
    }

    return sum;
}

/// L2 norm of a vector
fn vectorNorm(v: []const f32) f32 {
    return @sqrt(vectorDot(v, v));
}

// =============================================================================
// Tests
// =============================================================================

test "vectorDot basic" {
    const a = [_]f32{ 1, 2, 3, 4 };
    const b = [_]f32{ 5, 6, 7, 8 };
    const result = vectorDot(&a, &b);
    // 1*5 + 2*6 + 3*7 + 4*8 = 5 + 12 + 21 + 32 = 70
    try std.testing.expectApproxEqAbs(@as(f32, 70), result, 0.001);
}

test "vectorNorm" {
    const v = [_]f32{ 3, 4 };
    const result = vectorNorm(&v);
    // sqrt(9 + 16) = sqrt(25) = 5
    try std.testing.expectApproxEqAbs(@as(f32, 5), result, 0.001);
}

test "batchCosineSimilarity identical vectors" {
    const allocator = std.testing.allocator;
    const query = [_]f32{ 1, 0, 0 };
    const docs = [_]f32{ 1, 0, 0, 1, 0, 0 }; // 2 identical docs

    const result = try batchCosineSimilarity(allocator, &query, &docs, 3);
    defer allocator.free(result);

    try std.testing.expectEqual(@as(usize, 2), result.len);
    try std.testing.expectApproxEqAbs(@as(f32, 1.0), result[0], 0.001);
    try std.testing.expectApproxEqAbs(@as(f32, 1.0), result[1], 0.001);
}

test "batchL2Distance" {
    const allocator = std.testing.allocator;
    const query = [_]f32{ 0, 0, 0 };
    const docs = [_]f32{ 3, 4, 0 }; // 1 doc at distance 5

    const result = try batchL2Distance(allocator, &query, &docs, 3);
    defer allocator.free(result);

    try std.testing.expectEqual(@as(usize, 1), result.len);
    try std.testing.expectApproxEqAbs(@as(f32, 5.0), result[0], 0.001);
}

test "LogicTableContext basic" {
    const allocator = std.testing.allocator;
    var ctx = LogicTableContext.init(allocator);
    defer ctx.deinit();

    const data = [_]f32{ 1.0, 2.0, 3.0 };
    try ctx.bindColumn("docs", "embedding", &data);

    const retrieved = try ctx.getColumn("docs", "embedding");
    try std.testing.expectEqual(@as(usize, 3), retrieved.len);
    try std.testing.expectApproxEqAbs(@as(f32, 1.0), retrieved[0], 0.001);
}
